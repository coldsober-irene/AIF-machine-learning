{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNflDJiMeTNHonvfxEC0ztd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/AIF-machine-learning/blob/main/imageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "jBO7jVsK0bm9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "R1Ek0XSO0gpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L951Ww0SyZIA"
      },
      "outputs": [],
      "source": [
        "# LIBRARIES NEEDED\n",
        "import os \n",
        "import imghdr\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GATHER IMAGES\n",
        "image_path = \"/content/drive/MyDrive/data_for_study/images/class2\"\n",
        "classes = [\"irene\", \"messi\", \"mbappe\", \"neymar\"]\n",
        "extensions = ['jpeg', 'jpg', 'png', 'bmp']"
      ],
      "metadata": {
        "id": "5aXXa-DZyeh4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE DOGGY IMAGES\n",
        "[os.remove(os.path.join(image_path, class_, im)) for class_ in classes for im in os.listdir(os.path.join(image_path, class_)) if imghdr.what(os.path.join(image_path, class_, im)) not in extensions]\n",
        "all_images = {}\n",
        "for class_ in classes:\n",
        "    all_images[class_] = [os.path.join(os.path.join(image_path, class_, im)) for im in os.listdir(os.path.join(image_path, class_))]"
      ],
      "metadata": {
        "id": "ad3z0JSLzXoy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE DATASETS\n",
        "datasets = tf.keras.utils.image_dataset_from_directory(image_path) # this resize image to 256x256 and the batch size of 32\n",
        "# print(\"available batches in whole datasets : \", len(datasets)) # this helps when splitting the datasets (train, test & validate)\n",
        "# resize the pixel and move from being 0 to 255 and become 0 to 1: this minimize training data & computational cost\n",
        "datasets = datasets.map(lambda x, y: (x / 255, y))\n",
        "# to be able to access theses datasets\n",
        "# datasets =  datasets.as_numpy_iterator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4SvHLWtzfOo",
        "outputId": "bc9feae8-5c7d-4f25-8b78-4cc1488a42c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 247 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT DATA\n",
        "train_size = int(len(datasets) * .7) # these are batches\n",
        "test_size = int(len(datasets) * .1) + 1 # these are batches\n",
        "valid_size = int(len(datasets) * .2) # these are batches\n",
        "\n",
        "# Now take the exact batches in the datasets based on the number of batches for each category \n",
        "train = datasets.take(train_size) \n",
        "valid = datasets.skip(train_size).take(valid_size)\n",
        "test = datasets.skip(train_size + valid_size).take(test_size)"
      ],
      "metadata": {
        "id": "-5nov_84zqKl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL CREATION\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), 1, activation = 'relu', input_shape = (256,256,3)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(16, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# convert 2D into 1D\n",
        "model.add(Flatten())\n",
        "\n",
        "# HIDDEN LAYERS (FULL CONNECTED LAYERS)\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(1, activation = \"softmax\"))\n",
        "\n",
        "# COMPILE THE MODEL\n",
        "model.compile('adam', loss = tf.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
        "\n",
        "# see the summary of the model\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "qrHQKWhi0GFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN THE MODEL\n",
        "log_dir = \"/model_logs\"\n",
        "try:\n",
        "  os.mkdir(\"/model_logs\")\n",
        "except Exception:\n",
        "  pass \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir) # this is for tracking the performance of the model during training\n",
        "hist = model.fit(train, epochs = 11, validation_data = valid, callbacks = [tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoLis-j40N1g",
        "outputId": "e2a38076-2415-4067-8d42-660780c9e79c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "5/5 [==============================] - 18s 716ms/step - loss: 0.0000e+00 - accuracy: 0.2875 - val_loss: 0.0000e+00 - val_accuracy: 0.2812\n",
            "Epoch 2/11\n",
            "5/5 [==============================] - 4s 537ms/step - loss: 0.0000e+00 - accuracy: 0.2812 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 3/11\n",
            "5/5 [==============================] - 5s 692ms/step - loss: 0.0000e+00 - accuracy: 0.3125 - val_loss: 0.0000e+00 - val_accuracy: 0.1875\n",
            "Epoch 4/11\n",
            "5/5 [==============================] - 5s 693ms/step - loss: 0.0000e+00 - accuracy: 0.2812 - val_loss: 0.0000e+00 - val_accuracy: 0.3750\n",
            "Epoch 5/11\n",
            "5/5 [==============================] - 5s 690ms/step - loss: 0.0000e+00 - accuracy: 0.2688 - val_loss: 0.0000e+00 - val_accuracy: 0.2500\n",
            "Epoch 6/11\n",
            "5/5 [==============================] - 4s 540ms/step - loss: 0.0000e+00 - accuracy: 0.2812 - val_loss: 0.0000e+00 - val_accuracy: 0.1250\n",
            "Epoch 7/11\n",
            "5/5 [==============================] - 5s 695ms/step - loss: 0.0000e+00 - accuracy: 0.2625 - val_loss: 0.0000e+00 - val_accuracy: 0.2188\n",
            "Epoch 8/11\n",
            "5/5 [==============================] - 5s 691ms/step - loss: 0.0000e+00 - accuracy: 0.3000 - val_loss: 0.0000e+00 - val_accuracy: 0.2500\n",
            "Epoch 9/11\n",
            "5/5 [==============================] - 4s 544ms/step - loss: 0.0000e+00 - accuracy: 0.2625 - val_loss: 0.0000e+00 - val_accuracy: 0.4062\n",
            "Epoch 10/11\n",
            "5/5 [==============================] - 4s 537ms/step - loss: 0.0000e+00 - accuracy: 0.2750 - val_loss: 0.0000e+00 - val_accuracy: 0.3125\n",
            "Epoch 11/11\n",
            "5/5 [==============================] - 4s 535ms/step - loss: 0.0000e+00 - accuracy: 0.2500 - val_loss: 0.0000e+00 - val_accuracy: 0.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKE PREDICTION\n",
        "im1 = cv2.imread(\"/content/drive/MyDrive/data_for_study/file_from_db.png\")\n",
        "im2 = cv2.imread(\"/content/drive/MyDrive/data_for_study/mesi.jpg\")\n",
        "im11 = cv2.imread(\"/content/drive/MyDrive/others/WIN_20210709_115246.JPG\")\n",
        "im22 = cv2.imread(\"/content/drive/MyDrive/data_for_study/messii.jpg\")\n",
        "chris = cv2.imread(\"/content/drive/MyDrive/data_for_study/Cristiano_Ronaldo_2018.jpg\")\n",
        "other = cv2.imread(\"/content/drive/MyDrive/data_for_study/photo-1519238263530-99bdd11df2ea.jpg\")\n",
        "\n",
        "def process_img(imgs = []):\n",
        "  processed = []\n",
        "  for im in imgs:\n",
        "    im = tf.image.resize(im, (256, 256))\n",
        "    processed.append(np.expand_dims(im/255, 0))\n",
        "  return processed\n",
        "# CALL\n",
        "images = process_img(imgs = [im1, im2, im11, im22, chris, other])\n",
        "\n",
        "im1_pred = model.predict(images[0])\n",
        "im11_pred = model.predict(images[2])\n",
        "im2_pred = model.predict(images[1])\n",
        "im22_pred = model.predict(images[3])\n",
        "chris_pred = model.predict(images[-2])\n",
        "other_pred = model.predict(images[-1])\n",
        "\n",
        "print(\"irene prediction: \", im1_pred, im11_pred)\n",
        "print(\"messi prediction : \", im2_pred, im22_pred)\n",
        "print(\"christiano prediction: \", chris_pred)\n",
        "print(\"other prediction: \", other_pred)"
      ],
      "metadata": {
        "id": "_IO9kHuO0XNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.MaxPooling2D??"
      ],
      "metadata": {
        "id": "zypLxf8zC10J"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}